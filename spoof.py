from playwright.sync_api import sync_playwright
import time
import random

queryArray = [
        'how', 'what is', 'how to', 'is there any way', 'best way to', 'about', 'btw', 'by the way', 'ways of',
        'method for',
        'kind of', 'might be', 'letâ€™s', 'proxy', 'proxy setup', 'vpn vs proxy', 'variant', 'youtube', 'youtube tricks',
        'javascript tutorial', 'python scraping', 'learn hacking', 'online proxy tool', 'free proxy list',
        'web automation',
        'bypass firewall', 'youtube proxy', 'google tricks', 'tor browser', 'selenium bot', 'playwright python',
        'youtube video not loading', 'why does it', 'who created', 'history of', 'internet speed', 'wifi proxy',
        'streaming tricks', 'netflix alternative', 'vpn explained', 'cookie injection', 'session hijack',
        'browser automation',
        'proxy detection', 'scraping youtube', 'yt-dlp cookies', 'youtube autoplay fix', 'shadowban',
        'web scraping legal',
        'headless browser', 'browser fingerprinting', 'cybersecurity basics', 'data sniffing', 'python project',
        'learn ai',
        'chatgpt prompt', 'ai video generation', 'youtube shorts viral', 'best vpn 2025', 'anonymous browsing',
        'free wifi hack',
        'yt api quota', 'search engine tricks', 'trending now', 'most searched 2025', 'google dork', 'web crawler'
    ]

def playwright_to_netscape_cookie(playwright_cookies, output_file='cookies.txt'):

    netscape_header = "# Netscape HTTP Cookie File\n# This file was generated by Playwright cookie converter\n\n"

    converted_cookies = []
    for cookie in playwright_cookies:
        # Validate cookie
        if not isinstance(cookie, dict) or not all(key in cookie for key in ['name', 'value']):
            continue  # Skip invalid cookies
        if not cookie['name'].strip() or not cookie['value'].strip():
            continue  # Skip cookies with empty name or value

        # Extract fields with defaults
        name = str(cookie.get('name', '')).strip()
        value = str(cookie.get('value', '')).strip()
        domain = str(cookie.get('domain', '')).strip()
        include_subdomains = 'TRUE' if domain.startswith('.') else 'FALSE'
        path = str(cookie.get('path', '/')).strip() or '/'
        secure = 'TRUE' if cookie.get('secure', False) else 'FALSE'

        # Handle expires: -1 or invalid/missing becomes 0 (session cookie)
        expires = cookie.get('expires', 0)
        try:
            expires = int(float(expires)) if expires is not None else 0
            expires = 0 if expires <= 0 else expires  # Treat -1 or negative as session cookie
        except (ValueError, TypeError):
            expires = 0

        # Netscape format: domain, include_subdomains, path, secure, expires, name, value
        cookie_line = f"{domain}\t{include_subdomains}\t{path}\t{secure}\t{expires}\t{name}\t{value}"
        converted_cookies.append(cookie_line)

    # Write to file
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(netscape_header)
        for line in converted_cookies:
            f.write(line + '\n')

def parse_netscape_cookies(filename):
    cookies = []
    with open(filename, 'r') as f:
        for line in f:
            if line.startswith('#') or not line.strip():
                continue
            domain, flag, path, secure, expiration, name, value = line.strip().split('\t')
            cookies.append({
                'name': name,
                'value': value,
                'domain': domain,
                'path': path,
                'expires': int(expiration),
                'httpOnly': False,
                'secure': secure.lower() == 'true',
                'sameSite': 'Lax'  # adjust if needed
            })
    return cookies

def generate_random_query(words, max_word_count=5):
    count = random.randint(1, max_word_count)
    chosen_words = random.choices(words, k=count)
    return ' '.join(chosen_words)

with sync_playwright() as p:
    browser = p.chromium.launch(headless=False)
    context = browser.new_context()
    context.add_cookies(parse_netscape_cookies('cookies.txt'))

    page = context.new_page()

    delay_seconds = random.randint(60, 300)

    print(f"Delaying for {delay_seconds} seconds ({delay_seconds // 60} minutes)...")
    time.sleep(delay_seconds)

    page.goto("https://www.youtube.com/")

    end_time = time.time() + 20

    while time.time() < end_time:
        scroll_amount = random.randint(5, 30)
        page.mouse.wheel(0, scroll_amount)
        time.sleep(random.uniform(0.3, 0.7))

    time.sleep(2)
    query = generate_random_query(queryArray)

    page.goto(f'https://www.youtube.com/search?q={query}')

    scroll_time = time.time() + 20

    while time.time() < scroll_time:
        scroll_amount = random.randint(10, 20)
        page.mouse.wheel(0, scroll_amount)
        time.sleep(random.uniform(0.2, 0.5))

    time.sleep(4)

    playwright_to_netscape_cookie( context.cookies())
    print("cookies saved")
    browser.close()

if __name__ == "__main__":
    sync_playwright()
